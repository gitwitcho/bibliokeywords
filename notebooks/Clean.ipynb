{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Clean bibliographic datasets\n","- Read bibliographic datasets\n","- Select and rename columns\n","- Normalise entries\n","- Merge datasets into single dataset\n","- Clean dataset\n","- Write dataset to file\n","\n","**TODO**\n","- Add the possibility to switch off the logger output.\n","- Print some basic stats at the end of the code.\n","- Group the Scopus, Dimensions, and Lens operations so that they can be selected by an if statement in case the user doesn't specify all three (Scopus, Lens, Dimensions) directories."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import sys\n","\n","from pathlib import Path\n","\n","# Add the src directory to the Python path\n","src_path = Path(\"..\") / \"src\"\n","if src_path.resolve() not in sys.path:\n","    sys.path.insert(0, str(src_path.resolve()))\n","\n","from config import *\n","from utilities import *\n","from clean import *"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Input parameters\n","# -----------------------\n","biblio_project_dir = 'example_project'  # directory for the data and models of your bibliographic project\n","scopus_input_dir = 'raw/scopus'         # directory with Scopus data; leave empty if you don't have Scopus data\n","lens_input_dir = 'raw/lens'             # directory with Lens data; leave empty if you don't have Lens data\n","dims_input_dir = 'raw/dimensions'       # directory with Dimensions data; leave empty if you don't have Diemnsions data\n","\n","output_dir = 'processed'                # directory where you want to save the merged and cleaned bibliographic dataset\n","output_file = f'biblio_example_all.csv' # filename of the bibliographic dataset; leave empty if you don't want to save the data\n","\n","n_rows = 1000                              # the maxium number of rows read for each dataset; set to '0' if you want to read all the data\n","\n","write_cols = ['authors', 'title', 'abstract', 'year', 'pub_date', \n","              'n_cited', 'source', 'kws', 'fos', 'anzsrc_2020', \n","              'auth_affils', 'link', 'links', 'bib_src', 'scopus_id', \n","              'lens_id', 'dims_id']\n","# -----------------------"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-05-21 11:08:17,394 - Biblio - Reading 2 CSV files...\n","2023-05-21 11:08:17,443 - Biblio - File: scopus_example_1999_2017.csv, Size: 472 rows\n","2023-05-21 11:08:17,473 - Biblio - File: scopus_example_2018_2023.csv, Size: 520 rows\n","2023-05-21 11:08:17,491 - Biblio - Total number of publications in the dataframe: 992\n","2023-05-21 11:08:17,492 - Biblio - Reading 1 CSV files...\n","2023-05-21 11:08:17,520 - Biblio - File: lens_example.csv, Size: 1000 rows\n","2023-05-21 11:08:17,528 - Biblio - Total number of publications in the dataframe: 1000\n","2023-05-21 11:08:17,529 - Biblio - Reading 1 CSV files...\n","2023-05-21 11:08:17,576 - Biblio - File: dims_example.csv, Size: 999 rows\n","2023-05-21 11:08:17,592 - Biblio - Total number of publications in the dataframe: 999\n","2023-05-21 11:08:18,106 - Biblio - Number of publications in the input biblio_df: 2991\n"]},{"name":"stdout","output_type":"stream","text":["Removed 0 titles that were empty strings\n","Removed 0 titles that were NaN\n","Removed 8 records where the title contained \"conference\", \"workshop\", or \"proceeding\"\n","Removed additional 3 titles that were empty strings\n","Replaced 213 abtracts that were NaN with an empty string\n"]},{"name":"stderr","output_type":"stream","text":["2023-05-21 11:08:18,844 - Biblio - Number of publications before removing duplicate titles: 2980\n"]},{"name":"stdout","output_type":"stream","text":["Duplicate group: #2600 \r"]},{"name":"stderr","output_type":"stream","text":["2023-05-21 11:08:22,102 - Biblio - Number of publications after removing duplicate titles: 2668\n","2023-05-21 11:08:22,146 - Biblio - Writing biblio_df (2668 publications) to file 'biblio_example_all.csv'...\n"]}],"source":["# 1. Read the bibliographic datasets\n","scopus_df = read_biblio_csv_files_to_df(biblio_project_dir = biblio_project_dir, \n","                                        input_dir = scopus_input_dir,\n","                                        biblio_source = BiblioSource.SCOPUS,\n","                                        n_rows = n_rows)\n","\n","lens_df = read_biblio_csv_files_to_df(biblio_project_dir = biblio_project_dir, \n","                                      input_dir = lens_input_dir,\n","                                      biblio_source = BiblioSource.LENS,\n","                                      n_rows = n_rows)\n","\n","dims_df = read_biblio_csv_files_to_df(biblio_project_dir = biblio_project_dir, \n","                                      input_dir = dims_input_dir,\n","                                      biblio_source = BiblioSource.DIMS,\n","                                      n_rows = n_rows)\n","\n","# 2. Select and rename columns from the dataset\n","scopus_df = modify_cols_biblio_df(biblio_df_ = scopus_df, \n","                                  reshape_base = Reshape.SCOPUS_ALL)\n","\n","lens_df = modify_cols_biblio_df(biblio_df_ = lens_df, \n","                                reshape_base = Reshape.LENS_ALL)\n","\n","dims_df = modify_cols_biblio_df(biblio_df_ = dims_df, \n","                                reshape_base = Reshape.DIMS_ALL)\n","\n","# 3. Normalise key variables in the dataset (bib_src, links, keywords, authors, author-affils)\n","scopus_df = normalise_biblio_entities(biblio_df_ = scopus_df)\n","lens_df = normalise_biblio_entities(biblio_df_ = lens_df)\n","dims_df = normalise_biblio_entities(biblio_df_ = dims_df)\n","\n","# 4. Merge the datasets from Scopus, Lens, and Dimensions\n","biblio_df = merge_biblio_dfs(scopus_df, lens_df, dims_df)\n","\n","# 5. Clean the title and abstract, remove duplicate titles, and merge values from\n","#    different bibliographic datasets\n","biblio_df = clean_biblio_df(biblio_df_ = biblio_df)\n","\n","# 6. Optionally save the results\n","if output_file:\n","    write_df(biblio_df = biblio_df[write_cols],\n","            biblio_project_dir = biblio_project_dir,\n","            output_dir = output_dir,\n","            output_file = output_file)\n"]}],"metadata":{"kernelspec":{"display_name":"ml-plus-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
